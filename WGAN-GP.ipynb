{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26b93ccb",
   "metadata": {},
   "source": [
    "### Training the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003714f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from torch.nn.utils import spectral_norm\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# Configure logging to display information messages during training\n",
    "# Format: Timestamp Level: Message\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')\n",
    "\n",
    "\n",
    "# --- Reproducibility ---\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Sets the random seed for Python's random module, NumPy, and PyTorch\n",
    "    to ensure reproducibility of results across runs.\n",
    "    Args:\n",
    "        seed (int): The seed value to use.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # If CUDA (GPU support) is available, set the seed for all GPUs as well\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    logging.info(f\"Set random seed to {seed}\")\n",
    "\n",
    "\n",
    "# Set the seed for the entire script\n",
    "set_seed(42)\n",
    "\n",
    "\n",
    "# --- Dataset Definition ---\n",
    "\n",
    "class NPYDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for loading 3D data stored in NPY files.\n",
    "    Assumes the data contains discrete values {0, 1}.\n",
    "    The dataset handles loading, transposing, and providing individual samples.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_path: str):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "        Args:\n",
    "            data_path (str): The path to the .npy file containing the data.\n",
    "                             Expected original shape: [Depth, Height, Width, N]\n",
    "                             Expected values: {0, 1}\n",
    "        Raises:\n",
    "            FileNotFoundError: If the data file does not exist.\n",
    "            Exception: For other errors during data loading or processing.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load the data from the specified .npy file\n",
    "            # Assumes the raw data is stored as [Depth, Height, Width, N]\n",
    "            # For this specific dataset 'twocat.npy', the shape is (16, 128, 128, 146)\n",
    "            logging.info(f\"Loading data from {data_path}...\")\n",
    "            data = np.load(data_path)\n",
    "            logging.info(f\"Original data shape: {data.shape}\") # Expected: (16, 128, 128, 146)\n",
    "            # Check data values (optional but good for verification)\n",
    "            unique_values = np.unique(data)\n",
    "            logging.info(f\"Unique values in data: {unique_values}\")\n",
    "            if not np.all(np.isin(unique_values, [0, 1])):\n",
    "                 logging.warning(f\"Data contains values other than {{0, 1}}: {unique_values}. Ensure this is expected.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            logging.error(f\"Data file not found at {data_path}\")\n",
    "            raise FileNotFoundError(f\"Data file not found at {data_path}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading data: {e}\")\n",
    "            raise Exception(f\"Error loading data: {e}\")\n",
    "\n",
    "        # Transpose data to the PyTorch standard format [N, Depth, Height, Width]\n",
    "        # (3, 0, 1, 2) maps the original axes (D, H, W, N) to (N, D, H, W)\n",
    "        self.data = np.transpose(data, (3, 0, 1, 2))\n",
    "        logging.info(f\"Transposed data shape (N, D, H, W): {self.data.shape}\") # Expected: (146, 16, 128, 128)\n",
    "\n",
    "        # IMPORTANT: Data values remain {0, 1}. They will be converted to float\n",
    "        # tensors in __getitem__ and potentially scaled/shifted later if needed\n",
    "        # by the model or loss function (though WGAN-GP doesn't strictly require [-1, 1]).\n",
    "        # The Generator uses Sigmoid, outputting [0, 1], which matches the {0, 1} target well.\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of samples (N) in the dataset.\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a single sample from the dataset at the given index.\n",
    "        Args:\n",
    "            idx (int): The index of the sample to retrieve.\n",
    "        Returns:\n",
    "            torch.Tensor: A tensor representing the sample, with shape [Depth, Height, Width].\n",
    "                          The tensor will have dtype float32.\n",
    "        \"\"\"\n",
    "        # Get the data slice for the given index and convert it to a PyTorch tensor.\n",
    "        # Convert to float because neural networks typically work with floating-point numbers.\n",
    "        sample = torch.from_numpy(self.data[idx]).float()\n",
    "        # Shape returned: [16, 128, 128]\n",
    "        return sample\n",
    "\n",
    "\n",
    "# --- Generator Network ---\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generator network (G) for the GAN.\n",
    "    Takes a random latent vector as input and generates a 3D data sample\n",
    "    with the target shape [1, Depth, Height, Width], specifically [1, 16, 128, 128].\n",
    "    Uses ConvTranspose3d layers for upsampling.\n",
    "    Outputs values in the range [0, 1] using Sigmoid activation, suitable for {0, 1} data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim=100):\n",
    "        \"\"\"\n",
    "        Initializes the Generator layers.\n",
    "        Args:\n",
    "            latent_dim (int): The dimensionality of the input random noise vector.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim # Store latent dimension size\n",
    "\n",
    "        # Define the sequential network structure\n",
    "        self.net = nn.Sequential(\n",
    "            # 1. Fully Connected Layer: Project latent vector to a larger size suitable for reshaping\n",
    "            # Input: [batch_size, latent_dim] (e.g., [B, 100])\n",
    "            # Output: [batch_size, 512 * 2 * 8 * 8] (e.g., [B, 65536])\n",
    "            nn.Linear(latent_dim, 512 * 2 * 8 * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True), # Apply activation\n",
    "\n",
    "            # 2. Unflatten/Reshape: Convert the 1D vector into a 4D tensor (Channels, Depth, Height, Width)\n",
    "            # Input: [batch_size, 512 * 2 * 8 * 8]\n",
    "            # Output: [batch_size, 512, 2, 8, 8]\n",
    "            nn.Unflatten(1, (512, 2, 8, 8)),\n",
    "\n",
    "            # 3. First Upsampling Block (ConvTranspose3d, BatchNorm, LeakyReLU)\n",
    "            # Doubles Depth, Height, and Width dimensions (approximately, due to kernel/stride/padding)\n",
    "            # Input: [B, 512, 2, 8, 8]\n",
    "            # Output: [B, 256, 4, 16, 16] (D: (2-1)*2+4-2*1 = 4, H/W: (8-1)*2+4-2*1=14+4-2=16)\n",
    "            nn.ConvTranspose3d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(256), # Stabilize training\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 4. Second Upsampling Block\n",
    "            # Input: [B, 256, 4, 16, 16]\n",
    "            # Output: [B, 128, 8, 32, 32] (D: (4-1)*2+4-2*1 = 8, H/W: (16-1)*2+4-2*1=30+4-2=32)\n",
    "            nn.ConvTranspose3d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 5. Third Upsampling Block\n",
    "            # Input: [B, 128, 8, 32, 32]\n",
    "            # Output: [B, 64, 16, 64, 64] (D: (8-1)*2+4-2*1 = 16, H/W: (32-1)*2+4-2*1=62+4-2=64)\n",
    "            nn.ConvTranspose3d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 6. Final Upsampling Layer (Output Layer)\n",
    "            # Custom kernel/stride/padding to reach the exact target dimensions [1, 16, 128, 128]\n",
    "            # Stride (1, 2, 2) only upsamples H and W.\n",
    "            # Input: [B, 64, 16, 64, 64]\n",
    "            # Output: [B, 1, 16, 128, 128]\n",
    "            # D: (16-1)*1 + 1*(3-1) + 1 - 2*1 = 15 + 2 + 1 - 2 = 16\n",
    "            # H/W: (64-1)*2 + 1*(4-1) + 1 - 2*1 = 63*2 + 3 + 1 - 2 = 126 + 3 + 1 - 2 = 128\n",
    "            nn.ConvTranspose3d(64, 1, kernel_size=(3, 4, 4), stride=(1, 2, 2), padding=1),\n",
    "\n",
    "            # 7. Sigmoid Activation: Squash output values to the range [0, 1]\n",
    "            # This is suitable for generating data that should mimic the input {0, 1} values.\n",
    "            # The output can then be rounded to get discrete {0, 1} values.\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the Generator.\n",
    "        Args:\n",
    "            z (torch.Tensor): Input latent noise tensor, shape [batch_size, latent_dim].\n",
    "        Returns:\n",
    "            torch.Tensor: Generated 3D sample, shape [batch_size, 1, 16, 128, 128].\n",
    "        \"\"\"\n",
    "        return self.net(z)\n",
    "\n",
    "\n",
    "# --- Discriminator Network ---\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminator network (D) or Critic for the GAN.\n",
    "    Takes a 3D data sample (real or generated) as input and outputs a single scalar value (critic score).\n",
    "    Uses Conv3d layers for downsampling.\n",
    "    Applies Spectral Normalization to convolutional and linear layers to stabilize training (helps enforce Lipschitz constraint).\n",
    "    Does NOT use a final activation function (like Sigmoid), typical for WGAN critics.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the Discriminator layers.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Define the sequential network structure\n",
    "        self.net = nn.Sequential(\n",
    "            # 1. First Convolutional Block (SpectralNorm Conv3d, LeakyReLU)\n",
    "            # Input: [B, 1, 16, 128, 128] (Channel, Depth, Height, Width)\n",
    "            # Output: [B, 64, 8, 64, 64] (Halves D, H, W)\n",
    "            # spectral_norm helps stabilize training by controlling the Lipschitz constant\n",
    "            spectral_norm(nn.Conv3d(1, 64, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 2. Second Convolutional Block\n",
    "            # Input: [B, 64, 8, 64, 64]\n",
    "            # Output: [B, 128, 4, 32, 32] (Halves D, H, W)\n",
    "            spectral_norm(nn.Conv3d(64, 128, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 3. Third Convolutional Block\n",
    "            # Input: [B, 128, 4, 32, 32]\n",
    "            # Output: [B, 256, 2, 16, 16] (Halves D, H, W)\n",
    "            spectral_norm(nn.Conv3d(128, 256, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 4. Fourth Convolutional Block\n",
    "            # Input: [B, 256, 2, 16, 16]\n",
    "            # Output: [B, 512, 1, 8, 8] (Halves D, H, W)\n",
    "            spectral_norm(nn.Conv3d(256, 512, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 5. Flatten: Convert the 4D feature map into a 1D vector\n",
    "            # Input: [B, 512, 1, 8, 8]\n",
    "            # Output: [B, 512 * 1 * 8 * 8] = [B, 32768]\n",
    "            nn.Flatten(),\n",
    "\n",
    "            # 6. Final Linear Layer: Output a single scalar value (the critic score)\n",
    "            # Input: [B, 32768]\n",
    "            # Output: [B, 1]\n",
    "            # No activation function (linear output) as required by WGAN.\n",
    "            spectral_norm(nn.Linear(512 * 1 * 8 * 8, 1))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the Discriminator.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input 3D sample, shape [batch_size, 1, 16, 128, 128].\n",
    "        Returns:\n",
    "            torch.Tensor: Critic score, shape [batch_size, 1].\n",
    "        \"\"\"\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# --- WGAN-GP Trainer ---\n",
    "\n",
    "class WGANTrainer:\n",
    "    \"\"\"\n",
    "    Trainer class for Wasserstein GAN with Gradient Penalty (WGAN-GP).\n",
    "    Manages the training process, including optimizer steps, loss calculations,\n",
    "    and gradient penalty computation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, generator, discriminator, device, lambda_gp=10, n_critic=5, latent_dim=100):\n",
    "        \"\"\"\n",
    "        Initializes the trainer.\n",
    "        Args:\n",
    "            generator (nn.Module): The Generator network instance.\n",
    "            discriminator (nn.Module): The Discriminator network instance.\n",
    "            device (torch.device): The device to run training on (CPU or CUDA).\n",
    "            lambda_gp (int): The weight coefficient for the gradient penalty term in the loss.\n",
    "            n_critic (int): The number of times to train the Discriminator for each Generator update.\n",
    "            latent_dim (int): The dimensionality of the latent space.\n",
    "        \"\"\"\n",
    "        self.generator = generator.to(device)\n",
    "        self.discriminator = discriminator.to(device)\n",
    "        self.device = device\n",
    "        self.lambda_gp = lambda_gp # Gradient penalty coefficient\n",
    "        self.n_critic = n_critic   # Number of discriminator updates per generator update\n",
    "        self.latent_dim = latent_dim # Dimension of noise vector\n",
    "\n",
    "        # Optimizers: Adam is commonly used for GANs. Betas (0.5, 0.9) are often recommended.\n",
    "        self.g_optimizer = optim.Adam(generator.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "        self.d_optimizer = optim.Adam(discriminator.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "        logging.info(f\"WGANTrainer initialized with lambda_gp={lambda_gp}, n_critic={n_critic}\")\n",
    "\n",
    "    def compute_gradient_penalty(self, real_samples, fake_samples):\n",
    "        \"\"\"\n",
    "        Calculates the gradient penalty loss for WGAN-GP.\n",
    "        The penalty encourages the norm of the critic's gradient with respect to its input\n",
    "        to be close to 1 for points interpolated between real and fake samples.\n",
    "        This helps enforce the 1-Lipschitz constraint required by Wasserstein distance.\n",
    "\n",
    "        Args:\n",
    "            real_samples (torch.Tensor): Batch of real data samples.\n",
    "            fake_samples (torch.Tensor): Batch of generated (fake) samples.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The computed gradient penalty (scalar tensor).\n",
    "        \"\"\"\n",
    "        batch_size = real_samples.size(0)\n",
    "        # Generate random weights (epsilon) for interpolation, shape [batch_size, 1, 1, 1, 1]\n",
    "        # The extra dimensions match the sample dimensions [N, C, D, H, W] for broadcasting.\n",
    "        epsilon = torch.rand(batch_size, 1, 1, 1, 1, device=self.device)\n",
    "        epsilon = epsilon.expand_as(real_samples) # Expand to match sample shape\n",
    "\n",
    "        # Create interpolated samples between real and fake data\n",
    "        interpolates = (epsilon * real_samples + (1 - epsilon) * fake_samples).requires_grad_(True)\n",
    "\n",
    "        # Get the critic scores for these interpolated samples\n",
    "        d_interpolates = self.discriminator(interpolates)\n",
    "\n",
    "        # Create a tensor of ones as the target for gradient computation\n",
    "        # We want the gradient of the critic's output w.r.t. its input.\n",
    "        fake_output_targets = torch.ones(batch_size, 1, device=self.device, requires_grad=False)\n",
    "\n",
    "        # Calculate gradients of d_interpolates with respect to the interpolates themselves\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=d_interpolates,         # Scalar output for which we need gradients\n",
    "            inputs=interpolates,            # Input tensor w.r.t. which gradients are computed\n",
    "            grad_outputs=fake_output_targets, # Gradient of the loss w.r.t. outputs (d_interpolates), here just 1s\n",
    "            create_graph=True,              # Create graph for potential higher-order derivatives (needed for GP)\n",
    "            retain_graph=True,              # Retain graph as gradients are needed for both D and G updates potentially\n",
    "            only_inputs=True                # Only compute gradients w.r.t. specified inputs (interpolates)\n",
    "        )[0] # Get the first element (gradients w.r.t. interpolates)\n",
    "\n",
    "        # Reshape gradients from [B, C, D, H, W] to [B, -1] to easily compute the norm per sample\n",
    "        gradients = gradients.view(batch_size, -1)\n",
    "\n",
    "        # Calculate the gradient penalty: (||\\nabla D(interpolates)||_2 - 1)^2\n",
    "        # The L2 norm is calculated per sample (dim=1)\n",
    "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() # Average over the batch\n",
    "        return gradient_penalty\n",
    "\n",
    "    def train_step(self, real_samples):\n",
    "        \"\"\"\n",
    "        Performs a single training step, updating both the Discriminator and Generator.\n",
    "\n",
    "        Args:\n",
    "            real_samples (torch.Tensor): A batch of real data samples from the dataset,\n",
    "                                         already on the correct device and with channel dim added.\n",
    "                                         Shape: [batch_size, 1, Depth, Height, Width]\n",
    "\n",
    "        Returns:\n",
    "            tuple[float, float]: A tuple containing the Discriminator loss and Generator loss for this step.\n",
    "        \"\"\"\n",
    "        batch_size = real_samples.size(0)\n",
    "\n",
    "        # --- Train Discriminator (Critic) ---\n",
    "        # Train the critic n_critic times for each generator update\n",
    "        d_loss_total = 0.0\n",
    "        for _ in range(self.n_critic):\n",
    "            self.d_optimizer.zero_grad() # Clear previous gradients\n",
    "\n",
    "            # 1. Generate fake samples using the *current* generator\n",
    "            # Create random noise vector z\n",
    "            z = torch.randn(batch_size, self.latent_dim, device=self.device)\n",
    "            # Generate fake samples (output shape: [B, 1, D, H, W])\n",
    "            # Use .detach() to prevent gradients from flowing back to the generator during discriminator training\n",
    "            fake_samples = self.generator(z).detach()\n",
    "\n",
    "            # 2. Compute critic scores for real and fake samples\n",
    "            real_validity = self.discriminator(real_samples) # Score for real samples\n",
    "            fake_validity = self.discriminator(fake_samples) # Score for fake samples\n",
    "\n",
    "            # 3. Compute Gradient Penalty\n",
    "            gradient_penalty = self.compute_gradient_penalty(real_samples.data, fake_samples.data)\n",
    "\n",
    "            # 4. Compute Discriminator Loss (WGAN-GP loss)\n",
    "            # Loss = E[D(fake)] - E[D(real)] + lambda * GradientPenalty\n",
    "            # We want to maximize (D(real) - D(fake)), which is equivalent to minimizing (D(fake) - D(real))\n",
    "            d_loss = fake_validity.mean() - real_validity.mean() + self.lambda_gp * gradient_penalty\n",
    "            d_loss_total += d_loss.item() # Accumulate loss value for logging\n",
    "\n",
    "            # 5. Backward pass and optimizer step\n",
    "            d_loss.backward()           # Compute gradients\n",
    "            self.d_optimizer.step()     # Update discriminator weights\n",
    "\n",
    "        # Average D loss over n_critic steps for reporting\n",
    "        d_loss_avg = d_loss_total / self.n_critic\n",
    "\n",
    "        # --- Train Generator ---\n",
    "        self.g_optimizer.zero_grad() # Clear previous generator gradients\n",
    "\n",
    "        # 1. Generate a new batch of fake samples (NO detach this time)\n",
    "        z = torch.randn(batch_size, self.latent_dim, device=self.device)\n",
    "        fake_samples = self.generator(z)\n",
    "\n",
    "        # 2. Compute critic scores for the new fake samples\n",
    "        fake_validity = self.discriminator(fake_samples)\n",
    "\n",
    "        # 3. Compute Generator Loss\n",
    "        # Loss = -E[D(fake)]\n",
    "        # The generator wants to maximize the discriminator's score for fake samples (fool the discriminator),\n",
    "        # which is equivalent to minimizing the negative score.\n",
    "        g_loss = -fake_validity.mean()\n",
    "\n",
    "        # 4. Backward pass and optimizer step\n",
    "        g_loss.backward()         # Compute gradients for the generator\n",
    "        self.g_optimizer.step()   # Update generator weights\n",
    "\n",
    "        # Return the scalar loss values for logging/monitoring\n",
    "        return d_loss_avg, g_loss.item()\n",
    "\n",
    "    def generate_samples(self, num_samples: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Generates samples using the trained generator and maps them to discrete {0, 1} values.\n",
    "\n",
    "        Args:\n",
    "            num_samples (int): The number of samples to generate.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: A tensor containing the generated discrete samples,\n",
    "                          shape [num_samples, 1, Depth, Height, Width], values {0., 1.}.\n",
    "        \"\"\"\n",
    "        self.generator.eval() # Set generator to evaluation mode (disables dropout/batchnorm updates)\n",
    "        samples = None # Initialize samples variable\n",
    "        with torch.no_grad(): # Disable gradient calculation for inference\n",
    "            # Create random noise vectors\n",
    "            z = torch.randn(num_samples, self.latent_dim, device=self.device)\n",
    "            # Generate samples (output range is [0, 1] due to Sigmoid)\n",
    "            samples = self.generator(z)\n",
    "\n",
    "            # Map continuous [0, 1] output to discrete {0, 1} values\n",
    "            # Since the generator outputs values between 0 and 1 (due to Sigmoid),\n",
    "            # we can simply round the output to the nearest integer (0 or 1).\n",
    "            samples = samples.round() # Rounds to 0. or 1.\n",
    "\n",
    "            # Optional: Clamp values just in case of any numerical instability, though Sigmoid should guarantee [0, 1]\n",
    "            # samples = samples.clamp(0, 1) # Ensure values are strictly within [0, 1] before rounding (if not using round directly)\n",
    "\n",
    "\n",
    "        self.generator.train() # Set generator back to training mode\n",
    "        # Return samples on the device they were generated on (likely GPU)\n",
    "        # Shape: [num_samples, 1, 16, 128, 128]\n",
    "        return samples\n",
    "\n",
    "\n",
    "# --- Visualization ---\n",
    "\n",
    "class VisualizationManager:\n",
    "    \"\"\"\n",
    "    Manages saving visualization of generated samples during training.\n",
    "    Creates a timestamped directory for each run.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, save_dir: str = \"results\"):\n",
    "        \"\"\"\n",
    "        Initializes the manager and creates the save directory.\n",
    "        Args:\n",
    "            save_dir (str): The base directory where results will be saved.\n",
    "                            A timestamped subdirectory will be created inside this.\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\") # Generate timestamp string\n",
    "        self.save_dir = Path(save_dir) / timestamp # Create full path for the run\n",
    "        self.save_dir.mkdir(parents=True, exist_ok=True) # Create directory if it doesn't exist\n",
    "        logging.info(f\"Saving results to {self.save_dir}\")\n",
    "\n",
    "    def save_samples(self, samples: torch.Tensor, epoch: int, batch_idx: int):\n",
    "        \"\"\"\n",
    "        Saves a grid of slices from the generated 3D samples as a PNG image.\n",
    "\n",
    "        Args:\n",
    "            samples (torch.Tensor): Generated samples tensor (usually on GPU), values should be {0., 1.}.\n",
    "                                    Shape: [num_samples, 1, Depth, Height, Width]\n",
    "            epoch (int): Current epoch number.\n",
    "            batch_idx (int): Current batch index within the epoch.\n",
    "        \"\"\"\n",
    "        # Move samples to CPU and convert to NumPy array for plotting\n",
    "        samples = samples.cpu().numpy()\n",
    "        # Remove the channel dimension (C=1) for easier indexing\n",
    "        # Shape becomes: [num_samples, Depth, Height, Width]\n",
    "        samples = np.squeeze(samples, axis=1)\n",
    "\n",
    "        num_samples_to_plot = min(4, samples.shape[0]) # Plot at most 4 samples\n",
    "        num_slices_per_sample = 4 # Show 4 slices spaced evenly through the depth\n",
    "\n",
    "        # Create subplots: num_samples rows, num_slices columns\n",
    "        fig, axes = plt.subplots(num_samples_to_plot, num_slices_per_sample,\n",
    "                                 figsize=(num_slices_per_sample * 3, num_samples_to_plot * 3)) # Adjust figsize as needed\n",
    "\n",
    "        # Handle the case where only one sample is plotted (axes might not be a 2D array)\n",
    "        if num_samples_to_plot == 1:\n",
    "            axes = axes[np.newaxis, :]\n",
    "\n",
    "        # Determine indices for the slices to show (evenly spaced)\n",
    "        depth_indices = np.linspace(0, samples.shape[1] - 1, num_slices_per_sample, dtype=int)\n",
    "\n",
    "        # Iterate through the samples and slices to plot\n",
    "        for i in range(num_samples_to_plot):\n",
    "            for j, depth_idx in enumerate(depth_indices):\n",
    "                # Get the specific 2D slice [Height, Width]\n",
    "                slice_2d = samples[i, depth_idx]\n",
    "                # Display the slice using imshow\n",
    "                # cmap='viridis' is a common colormap, 'gray' might also be suitable for binary data\n",
    "                # vmin=0, vmax=1 ensures the color scale is fixed for {0, 1} data\n",
    "                im = axes[i, j].imshow(slice_2d, cmap='viridis', vmin=0, vmax=1)\n",
    "                axes[i, j].set_title(f\"Sample {i+1}, Depth {depth_idx}\")\n",
    "                axes[i, j].axis('off') # Hide axes ticks and labels\n",
    "\n",
    "        # Add a single colorbar for the entire figure\n",
    "        fig.colorbar(im, ax=axes.ravel().tolist(), shrink=0.7) # Adjust shrink as needed\n",
    "        fig.suptitle(f'Generated Samples - Epoch {epoch}, Batch {batch_idx}') # Overall title\n",
    "        fig.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent title overlap\n",
    "\n",
    "        # Save the figure to the run's directory\n",
    "        save_path = self.save_dir / f'samples_e{epoch}_b{batch_idx}.png'\n",
    "        plt.savefig(save_path)\n",
    "        plt.close(fig) # Close the figure to free memory\n",
    "        # logging.debug(f\"Saved sample visualization to {save_path}\") # Use debug level for less verbose logging\n",
    "\n",
    "\n",
    "# --- Checkpoint Loading ---\n",
    "\n",
    "def load_checkpoint(checkpoint_path, generator, discriminator, trainer):\n",
    "    \"\"\"\n",
    "    Loads model weights, optimizer states, and epoch number from a checkpoint file.\n",
    "\n",
    "    Args:\n",
    "        checkpoint_path (str or Path): Path to the checkpoint file (.pt).\n",
    "        generator (nn.Module): The Generator model instance.\n",
    "        discriminator (nn.Module): The Discriminator model instance.\n",
    "        trainer (WGANTrainer): The WGANTrainer instance containing optimizers.\n",
    "\n",
    "    Returns:\n",
    "        int: The epoch number to start training from (last saved epoch + 1).\n",
    "             Returns 0 if the checkpoint is not found or fails to load.\n",
    "    \"\"\"\n",
    "    start_epoch = 0\n",
    "    checkpoint_path = Path(checkpoint_path) # Ensure it's a Path object\n",
    "    if checkpoint_path.is_file():\n",
    "        try:\n",
    "            logging.info(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "            # Load checkpoint onto the device specified in the trainer\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=trainer.device)\n",
    "\n",
    "            # Load state dictionaries\n",
    "            generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "            discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
    "            trainer.g_optimizer.load_state_dict(checkpoint['g_optimizer_state_dict'])\n",
    "            trainer.d_optimizer.load_state_dict(checkpoint['d_optimizer_state_dict'])\n",
    "\n",
    "            # Load the epoch number (add 1 to start from the next epoch)\n",
    "            # Use .get with a default value for backward compatibility if 'epoch' key is missing\n",
    "            start_epoch = checkpoint.get('epoch', -1) + 1\n",
    "            logging.info(f\"Successfully loaded checkpoint. Resuming from epoch {start_epoch}\")\n",
    "\n",
    "        except FileNotFoundError: # This condition is checked by is_file(), but added for completeness\n",
    "            logging.warning(f\"Checkpoint file not found at {checkpoint_path}. Starting training from scratch.\")\n",
    "            start_epoch = 0\n",
    "        except KeyError as e:\n",
    "            logging.error(f\"Checkpoint file is missing key: {e}. Could not load checkpoint properly. Starting from scratch.\")\n",
    "            start_epoch = 0\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading checkpoint: {e}. Starting training from scratch.\")\n",
    "            start_epoch = 0\n",
    "    else:\n",
    "        logging.warning(f\"Checkpoint path '{checkpoint_path}' not found. Starting training from scratch.\")\n",
    "        start_epoch = 0\n",
    "\n",
    "    return start_epoch\n",
    "\n",
    "\n",
    "# --- Main Training Function ---\n",
    "\n",
    "def train(data_path: str, num_epochs: int, batch_size: int = 96, checkpoint_path=None, save_interval: int = 50, log_interval: int = 100):\n",
    "    \"\"\"\n",
    "    Main function to set up and run the WGAN-GP training loop.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Path to the NPY data file.\n",
    "        num_epochs (int): Total number of epochs to train for.\n",
    "        batch_size (int): Number of samples per batch.\n",
    "        checkpoint_path (str, optional): Path to a checkpoint file to resume training from. Defaults to None.\n",
    "        save_interval (int): Save a checkpoint every `save_interval` epochs.\n",
    "        log_interval (int): Log training progress and save sample visualization every `log_interval` batches.\n",
    "    \"\"\"\n",
    "    # 1. Setup Device (GPU if available, otherwise CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logging.info(f\"Using device: {device}\")\n",
    "\n",
    "    # 2. Load Dataset and Create DataLoader\n",
    "    try:\n",
    "        dataset = NPYDataset(data_path)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to initialize dataset: {e}\")\n",
    "        return # Exit if dataset cannot be loaded\n",
    "\n",
    "    # Determine number of workers based on OS (common practice)\n",
    "    num_workers = 4 if os.name == 'posix' else 0 # Use workers on Linux/Mac, 0 on Windows usually safer\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,       # Shuffle data each epoch for better training\n",
    "        num_workers=num_workers, # Use multiple processes to load data if available\n",
    "        pin_memory=True     # Speeds up data transfer to GPU if using CUDA\n",
    "    )\n",
    "    logging.info(f\"DataLoader created with batch size {batch_size}, num workers {num_workers}\")\n",
    "\n",
    "    # 3. Initialize Models, Trainer, and Visualization Manager\n",
    "    generator = Generator()\n",
    "    discriminator = Discriminator()\n",
    "    trainer = WGANTrainer(generator, discriminator, device) # n_critic=5 by default\n",
    "    vis_manager = VisualizationManager() # Saves results in './results/<timestamp>/'\n",
    "\n",
    "    # 4. Load Checkpoint if specified\n",
    "    start_epoch = 0\n",
    "    if checkpoint_path:\n",
    "        start_epoch = load_checkpoint(checkpoint_path, generator, discriminator, trainer)\n",
    "\n",
    "    # 5. Training Loop\n",
    "    logging.info(f\"Starting training from epoch {start_epoch} for {num_epochs} epochs...\")\n",
    "    d_losses = [] # List to store discriminator losses per step\n",
    "    g_losses = [] # List to store generator losses per step\n",
    "    best_g_loss = float('inf') # Track the best generator loss observed so far for saving the 'best' model\n",
    "\n",
    "    for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "        # Set models to training mode at the start of each epoch\n",
    "        generator.train()\n",
    "        discriminator.train()\n",
    "\n",
    "        for batch_idx, real_samples in enumerate(dataloader):\n",
    "            # Prepare real samples:\n",
    "            # - Add channel dimension: [B, D, H, W] -> [B, 1, D, H, W]\n",
    "            # - Ensure float type (already done in dataset, but good practice)\n",
    "            # - Move to the training device\n",
    "            real_samples = real_samples.unsqueeze(1).float().to(device)\n",
    "\n",
    "            # Perform one training step (updates D and G)\n",
    "            d_loss, g_loss = trainer.train_step(real_samples)\n",
    "\n",
    "            # Record losses\n",
    "            d_losses.append(d_loss)\n",
    "            g_losses.append(g_loss)\n",
    "\n",
    "            # Logging and Visualization (periodically)\n",
    "            if batch_idx % log_interval == 0:\n",
    "                logging.info(\n",
    "                    f\"Epoch [{epoch}/{start_epoch + num_epochs - 1}] \"\n",
    "                    f\"Batch [{batch_idx}/{len(dataloader)}] \"\n",
    "                    f\"D Loss: {d_loss:.4f}, G Loss: {g_loss:.4f}\"\n",
    "                )\n",
    "                # Generate and save sample visualizations\n",
    "                # Generate a small number of samples (e.g., 4)\n",
    "                samples_to_visualize = trainer.generate_samples(4)\n",
    "                vis_manager.save_samples(samples_to_visualize, epoch, batch_idx)\n",
    "\n",
    "                # Save the 'best' model based on Generator loss (heuristic)\n",
    "                # Lower G loss might indicate better generation quality, but should be verified visually.\n",
    "                if g_loss < best_g_loss:\n",
    "                    best_g_loss = g_loss\n",
    "                    best_model_path = vis_manager.save_dir / 'best_model.pt'\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'generator_state_dict': trainer.generator.state_dict(),\n",
    "                        'discriminator_state_dict': trainer.discriminator.state_dict(),\n",
    "                        'g_optimizer_state_dict': trainer.g_optimizer.state_dict(),\n",
    "                        'd_optimizer_state_dict': trainer.d_optimizer.state_dict(),\n",
    "                        'g_loss': g_loss, # Store the loss value for reference\n",
    "                        'd_loss': d_loss,\n",
    "                    }, best_model_path)\n",
    "                    logging.info(f\"Saved new best model (G Loss: {g_loss:.4f}) at Epoch {epoch}, Batch {batch_idx} to {best_model_path}\")\n",
    "\n",
    "        # Save Checkpoint (periodically at the end of an epoch)\n",
    "        if (epoch + 1) % save_interval == 0 or epoch == start_epoch + num_epochs - 1: # Save every save_interval epochs or on the last epoch\n",
    "            checkpoint_save_path = vis_manager.save_dir / f'checkpoint_epoch_{epoch}.pt'\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'generator_state_dict': trainer.generator.state_dict(),\n",
    "                'discriminator_state_dict': trainer.discriminator.state_dict(),\n",
    "                'g_optimizer_state_dict': trainer.g_optimizer.state_dict(),\n",
    "                'd_optimizer_state_dict': trainer.d_optimizer.state_dict(),\n",
    "            }, checkpoint_save_path)\n",
    "            logging.info(f\"Saved checkpoint at {checkpoint_save_path}\")\n",
    "\n",
    "    # 6. Post-Training: Plot and save loss curves\n",
    "    logging.info(\"Training finished. Plotting loss curves...\")\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(d_losses, label='Discriminator Loss (Avg per G step)')\n",
    "    plt.plot(g_losses, label='Generator Loss')\n",
    "    plt.xlabel('Training Step')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('WGAN-GP Training Losses')\n",
    "    loss_curve_path = vis_manager.save_dir / 'loss_curve.png'\n",
    "    plt.savefig(loss_curve_path)\n",
    "    plt.close()\n",
    "    logging.info(f\"Loss curve saved to {loss_curve_path}\")\n",
    "    logging.info(f\"All results saved in {vis_manager.save_dir}\")\n",
    "\n",
    "\n",
    "# --- Script Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Parameters ---\n",
    "    DATA_FILE = \"twocat.npy\"       # Name of your input data file (must be in the same directory or provide full path)\n",
    "    NUM_EPOCHS = 2000             # Total number of epochs for training\n",
    "    BATCH_SIZE = 64              # Batch size (adjust based on GPU memory) - 96 might be too large for some GPUs\n",
    "    # CHECKPOINT_TO_LOAD = None     # Set to None to train from scratch\n",
    "    CHECKPOINT_TO_LOAD = \"results/20231115_103000/checkpoint_epoch_1999.pt\" # Example: Path to a checkpoint file to resume from\n",
    "                                                                             # Replace with your actual checkpoint path if needed\n",
    "    SAVE_EVERY_N_EPOCHS = 100     # How often to save a checkpoint\n",
    "    LOG_EVERY_N_BATCHES = 100     # How often to log loss and save sample images\n",
    "\n",
    "    # --- Start Training ---\n",
    "    # Check if data file exists before starting\n",
    "    if not Path(DATA_FILE).is_file():\n",
    "        logging.error(f\"Data file '{DATA_FILE}' not found. Please ensure it is in the correct directory.\")\n",
    "    else:\n",
    "        train(\n",
    "            data_path=DATA_FILE,\n",
    "            num_epochs=NUM_EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            checkpoint_path=CHECKPOINT_TO_LOAD,\n",
    "            save_interval=SAVE_EVERY_N_EPOCHS,\n",
    "            log_interval=LOG_EVERY_N_BATCHES\n",
    "        )\n",
    "\n",
    "    # --- Example: How to load the best model and generate samples later ---\n",
    "    # best_model_path = \"results/<your_timestamp_folder>/best_model.pt\" # Replace with actual path\n",
    "    # if Path(best_model_path).is_file():\n",
    "    #     logging.info(f\"Loading best model from {best_model_path} for generation...\")\n",
    "    #     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #     generator = Generator().to(device)\n",
    "    #     checkpoint = torch.load(best_model_path, map_location=device)\n",
    "    #     generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "    #\n",
    "    #     # Need a WGANTrainer instance just to use the generate_samples method conveniently\n",
    "    #     # Or create a standalone generation function\n",
    "    #     dummy_discriminator = Discriminator().to(device) # Not actually used for generation\n",
    "    #     trainer_for_generation = WGANTrainer(generator, dummy_discriminator, device)\n",
    "    #\n",
    "    #     num_generated = 8\n",
    "    #     generated_samples = trainer_for_generation.generate_samples(num_generated)\n",
    "    #     logging.info(f\"Generated {num_generated} samples with shape: {generated_samples.shape}\")\n",
    "    #     # You can now save or further process 'generated_samples'\n",
    "    #     # Example: Save as numpy array\n",
    "    #     # np.save(\"generated_output.npy\", generated_samples.cpu().numpy())\n",
    "    # else:\n",
    "    #      logging.info(\"Best model checkpoint not found, skipping generation example.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
